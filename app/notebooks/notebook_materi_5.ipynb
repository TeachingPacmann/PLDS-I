{"cells":[{"cell_type":"markdown","id":"332cb105-b15c-4331-aff5-fa8e9f931e73","metadata":{"id":"332cb105-b15c-4331-aff5-fa8e9f931e73"},"source":["# Import\n","\n","Import all packages that will be used"]},{"cell_type":"code","execution_count":1,"id":"15c459c3-beaa-4811-a74a-6cf3c3d337f5","metadata":{"id":"15c459c3-beaa-4811-a74a-6cf3c3d337f5"},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import sklearn\n","import joblib\n","import time\n","from string import punctuation"]},{"cell_type":"code","execution_count":2,"id":"e5a897f2-e73c-4845-ae1b-ce8a368827d8","metadata":{"id":"e5a897f2-e73c-4845-ae1b-ce8a368827d8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, roc_auc_score, f1_score, plot_roc_curve, make_scorer\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.utils.class_weight import compute_class_weight\n","import lightgbm as lgb\n","\n","import nltk\n","from nltk.corpus import stopwords\n","\n","tqdm.pandas()"]},{"cell_type":"markdown","id":"481a03a2-ac38-46e0-8ec2-815ed8c7d983","metadata":{"id":"481a03a2-ac38-46e0-8ec2-815ed8c7d983"},"source":["# Load and Split Dataset\n","\n","Load and split dataset:\n","- Make each processing step as a function.\n","- Make main function.\n","- Make \"tuneable\" parameters"]},{"cell_type":"code","execution_count":3,"id":"e043c667-e114-49ae-af8e-8084ef28f023","metadata":{"id":"e043c667-e114-49ae-af8e-8084ef28f023"},"outputs":[],"source":["def split_xy(df, x_col, y_col):\n","    \"\"\"\n","    Splitting x and y variables.\n","    \n","    Args:\n","    - df(DataFrame): initial input dataframe\n","    - x_col(list): List of x variable columns\n","    - y_col(list): List of y variable columns\n","    \n","    Returns:\n","    - df[x_col](DataFrame): Dataframe contains x columns and id\n","    - df[y_col](DataFrame): Dataframe contains y columns and id\n","    \"\"\"\n","    x_col = ['id']+x_col\n","    y_col = ['id']+y_col\n","    return df[x_col], df[y_col]\n","\n","\n","def get_stratify_col(y, stratify_col):\n","    \"\"\"\n","    Splitting x and y variables.\n","    \n","    Args:\n","    - y(DataFrame): DataFrame contains target variables and id\n","    - stratify_col(str): column name of the reference column.\n","    \n","    Returns:\n","    - stratification: Dataframe contains column that will be used as stratification reference\n","    \"\"\"\n","    if stratify_col is None:\n","        stratification = None\n","    else:\n","        stratification = y[stratify_col]\n","    \n","    return stratification\n","\n","\n","def run_split_data(x, y, stratify_col=None, TEST_SIZE=0.2):\n","    \"\"\"\n","    Splitting x and y variables.\n","    \n","    Args:\n","    - y(DataFrame): DataFrame contains predictor variables and id\n","    - y(DataFrame): DataFrame contains target variables and id\n","    - stratify_col(str): column name of the reference column.\n","    - TEST_SIZE(float): Size of the test and validation dataset size.\n","    \n","    Returns:\n","    - x_blabla(DataFrame): X variables for train/valid/test dataset\n","    - y_blabla(DataFrame): Y variables for train/valid/test dataset\n","    \"\"\"\n","    strat_train = get_stratify_col(y, stratify_col)\n","    x_train, x_test, y_train, y_test = train_test_split(x, y,\n","                                       stratify = strat_train,\n","                                       test_size= TEST_SIZE*2,\n","                                       random_state= 42)\n","    \n","    strat_test = get_stratify_col(y_test, stratify_col)\n","    x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test,\n","                                       stratify = strat_test,\n","                                       test_size= 0.5,\n","                                       random_state= 42)\n","    \n","    return x_train, y_train, x_valid, y_valid, x_test, y_test"]},{"cell_type":"markdown","id":"464d88eb-190e-4979-8752-b6a473892a1a","metadata":{"id":"464d88eb-190e-4979-8752-b6a473892a1a"},"source":["### Main Function\n","\n","Main function for loading and splitting dataset. It runs:\n","- X & Y split\n","- Train-Valid-Test split with stratification"]},{"cell_type":"code","execution_count":4,"id":"2cfeb8d7-0fc7-4f59-8f3c-b138fbf748d7","metadata":{"id":"2cfeb8d7-0fc7-4f59-8f3c-b138fbf748d7"},"outputs":[],"source":["def main_load(params):\n","    df = pd.read_csv(params[\"file_loc\"])\n","    x_all, y_all = split_xy(df, [params['x_col']], [params['y_col']])\n","    x_train, y_train,x_valid, y_valid,x_test, y_test = run_split_data(x_all, y_all, \n","                                                                      params['stratify'], \n","                                                                      params['test_size'])\n","    joblib.dump(x_train, params[\"out_path\"]+\"x_train.pkl\")\n","    joblib.dump(y_train, params[\"out_path\"]+\"y_train.pkl\")\n","    joblib.dump(x_valid, params[\"out_path\"]+\"x_valid.pkl\")\n","    joblib.dump(y_valid, params[\"out_path\"]+\"y_valid.pkl\")\n","    joblib.dump(x_test, params[\"out_path\"]+\"x_test.pkl\")\n","    joblib.dump(y_test, params[\"out_path\"]+\"y_test.pkl\")\n","    \n","    return x_train, y_train, x_valid, y_valid, x_test, y_test"]},{"cell_type":"code","execution_count":5,"id":"f2e75dfa-260b-4dda-826b-b0c1b96e3b36","metadata":{"id":"f2e75dfa-260b-4dda-826b-b0c1b96e3b36"},"outputs":[],"source":["params = {'file_loc': '../data/comments_data.csv', \n","          'x_col':'comment_text', \n","          'y_col':'toxic', \n","          'stratify': 'toxic',\n","          'out_path': \"../output/\",\n","          'test_size':0.2}"]},{"cell_type":"code","execution_count":6,"id":"7cc1ef98-214b-426d-addd-edb21caa46c8","metadata":{"id":"7cc1ef98-214b-426d-addd-edb21caa46c8"},"outputs":[],"source":["x_train, y_train, x_valid, y_valid, x_test, y_test = main_load(params)"]},{"cell_type":"markdown","id":"9018251a-b54d-423b-b871-d8701866c3af","metadata":{"id":"9018251a-b54d-423b-b871-d8701866c3af"},"source":["# Data Preprocessing\n","Data preprocessing:\n","- Make each processing step as a function.\n","- Make main function.\n","- Make parameters for preprocessing on/off for experimentation."]},{"cell_type":"code","execution_count":7,"id":"cabd67a3-d2cd-4598-8317-0acfb1259c2b","metadata":{"id":"cabd67a3-d2cd-4598-8317-0acfb1259c2b"},"outputs":[],"source":["def lowercase_char(df_in, do=True):\n","    \"\"\"\n","    Function for lowercasing strings\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].str.lower()\n","    return df\n","\n","def phrase_decontraction(phrase):\n","    \"\"\"\n","    Function to decontract phrases\n","    \"\"\"\n","    # specific\n","    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n","\n","    # general\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n","    return phrase\n","\n","def decontract(df_in, do=True):\n","    \"\"\"\n","    Main function for decontracting phrases\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].apply(phrase_decontraction)\n","    return df\n","\n","def remove_numbers(df_in, do=True):\n","    \"\"\"\n","    Function for removing numbers from text\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].apply(lambda x: ''.join(string for string in x if not string.isdigit()))\n","    return df\n","\n","def remove_punc(df_in, do=True):\n","    \"\"\"\n","    Function for removing punctuation in text\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].str.replace(f'[{punctuation}]', ' ', regex=True )\n","    return df\n","\n","def remove_whitespace(df_in, do=True):\n","    \"\"\"\n","    Function for removing whitespace in text\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].apply(lambda x: \" \".join(x.split()))\n","    return df\n","\n","def remove_stop(df_in, eng_stopwords, do=True):\n","    \"\"\"\n","    Function for removing stopwords in text\n","    \"\"\"\n","    df = df_in.copy()  # Avoid modifying the main dataframe\n","    if do:\n","        df['comment_text'] = df['comment_text'].apply(lambda x: \" \".join([word for word in nltk.word_tokenize(x) if word not in eng_stopwords]))\n","    return df"]},{"cell_type":"markdown","id":"c5108e6d-99e9-445b-bd93-214eb23787a1","metadata":{"id":"c5108e6d-99e9-445b-bd93-214eb23787a1"},"source":["Make preprocess function which executes each of the preprocessing steps"]},{"cell_type":"code","execution_count":8,"id":"40a6ea43-7e0b-40c8-9fce-d4085472c574","metadata":{"id":"40a6ea43-7e0b-40c8-9fce-d4085472c574"},"outputs":[],"source":["def preprocess(df_in, params):\n","    \"\"\"\n","    A function to execute the preprocessing steps.\n","    \n","    Args:\n","    - df_in(DataFrame): Input dataframe\n","    - params(dict): preprocessing parameters\n","    \n","    Return:\n","    - df(DataFrame): preprocessed data\n","    \"\"\"\n","    eng_stopwords = stopwords.words('english')\n","    df = df_in.copy()\n","    df = lowercase_char(df, params['lowercase'])\n","    df = decontract(df, params['decontract'])\n","    df = remove_numbers(df, params['remove_num'])\n","    df = remove_punc(df, params['remove_punc'])\n","    df = remove_whitespace(df, params['remove_space'])\n","    df = remove_stop(df, eng_stopwords, params['remove_stop'])\n","    return df"]},{"cell_type":"markdown","id":"e21ed97c-8c02-4338-b986-c31ffab44a5d","metadata":{"id":"e21ed97c-8c02-4338-b986-c31ffab44a5d"},"source":["Main function, executing preprocessing for each train, valid, test dataset"]},{"cell_type":"code","execution_count":9,"id":"85477927-937c-41d3-84ed-2c9d0fe0e4b9","metadata":{"id":"85477927-937c-41d3-84ed-2c9d0fe0e4b9"},"outputs":[],"source":["def main_prep(x_train,x_valid,x_test, params):\n","    x_list = [x_train,x_valid,x_test]\n","\n","    x_preprocessed = []\n","    for x in tqdm(x_list):\n","        temp = preprocess(x, params)\n","        x_preprocessed.append(temp)\n","\n","    name = ['train','valid','test']\n","    for i,x in tqdm(enumerate(x_preprocessed)):\n","        joblib.dump(x, f\"{params['out_path']}x_{name[i]}_preprocessed.pkl\")\n","    \n","    return x_preprocessed"]},{"cell_type":"markdown","id":"e2e35b84-209a-484f-889a-57987a6f3fb8","metadata":{"id":"e2e35b84-209a-484f-889a-57987a6f3fb8"},"source":["Create a params variable which contains dictionary of which process should be turned on or off"]},{"cell_type":"code","execution_count":10,"id":"a2934405-9146-4f53-ae5f-50a749723645","metadata":{"id":"a2934405-9146-4f53-ae5f-50a749723645"},"outputs":[],"source":["params_preprocess = { 'lowercase': True, \n","                      'decontract':True, \n","                      'remove_num':True, \n","                      'remove_punc': True, \n","                      'remove_space': True, \n","                      'remove_stop': True, \n","                      'out_path': \"../output/\"}"]},{"cell_type":"code","execution_count":11,"id":"d34ee813-732e-45ab-a8b6-e25b9622428e","metadata":{"id":"d34ee813-732e-45ab-a8b6-e25b9622428e","outputId":"c793705e-e5c1-46f3-910e-23e906f4b84e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [01:56<00:00, 38.97s/it]\n","3it [00:00,  6.24it/s]\n"]}],"source":["x_preprocessed_list = main_prep(x_train,x_valid,x_test,params_preprocess)"]},{"cell_type":"markdown","id":"92eb8607-8bdf-4566-8f65-9a67cf4ab3c8","metadata":{"id":"92eb8607-8bdf-4566-8f65-9a67cf4ab3c8"},"source":["# Feature Engineering"]},{"cell_type":"markdown","id":"e9e0a269-79a1-4d50-84b7-7ac738ba6ff2","metadata":{"id":"e9e0a269-79a1-4d50-84b7-7ac738ba6ff2"},"source":["Create functions that perform feature engineering. In the current project, we only use tf-idf without additional step for feature creation or feature selection."]},{"cell_type":"code","execution_count":12,"id":"495fd56b-a0b5-45a6-afa1-20f7c5a8f4b9","metadata":{"id":"495fd56b-a0b5-45a6-afa1-20f7c5a8f4b9"},"outputs":[],"source":["def vectorize_tfidf(df_in, params, vectorizer=None):\n","    \"\"\"\n","    function to execute vectorization using tfidf\n","    \n","    Args:\n","    - df_in(DataFrame): Input data\n","    - params(dict): Vectorizer parameters\n","    - vectorizer(callable): tfidf vectorizer, default to None. \n","    If None, then the function will create a new tfidf vectorizer  \n","    \"\"\"\n","    df = df_in.copy()\n","    if vectorizer is None:  # fit to train data\n","        vectorizer = TfidfVectorizer(\n","            analyzer='word',\n","            stop_words='english',\n","            min_df = params['min_df']\n","        )\n","        vectorized = vectorizer.fit_transform(df['comment_text'])\n","        joblib.dump(vectorizer, f\"../output/{params['vectorizer_file']}.pkl\")\n","    else:\n","        vectorized = vectorizer.transform(df['comment_text'])\n","    \n","    vectorized_df = pd.DataFrame(vectorized.toarray(), \n","                                 columns=vectorizer.get_feature_names(), \n","                                 index = df.index)\n","    df_non_sentence = df.drop(['comment_text'],axis=1)\n","    df_final = pd.concat([vectorized_df, df_non_sentence],axis=1)\n","    return df_final, vectorizer"]},{"cell_type":"markdown","id":"03d490d9-fc05-4abe-81ca-93988897b6a3","metadata":{"id":"03d490d9-fc05-4abe-81ca-93988897b6a3"},"source":["Main function for executing feature engineering"]},{"cell_type":"code","execution_count":13,"id":"af9e4188-c9a8-48a9-b2ed-0d5b65f3e72f","metadata":{"id":"af9e4188-c9a8-48a9-b2ed-0d5b65f3e72f"},"outputs":[],"source":["def main_feat(x_preprocessed_list, params):\n","    \"\"\"\n","    Main function for feature engineering\n","    \"\"\"\n","    x_train_preprocessed, x_valid_preprocessed, x_test_preprocessed = x_preprocessed_list\n","    df_train_vect, vectorizer = vectorize_tfidf(x_train_preprocessed, params)\n","    df_valid_vect, _ = vectorize_tfidf(x_valid_preprocessed, params, vectorizer)\n","    df_test_vect, _ = vectorize_tfidf(x_test_preprocessed, params, vectorizer)\n","    joblib.dump(df_train_vect, f\"{params['out_path']}x_train_vect.pkl\")\n","    joblib.dump(df_valid_vect, f\"{params['out_path']}x_valid_vect.pkl\")\n","    joblib.dump(df_test_vect, f\"{params['out_path']}x_test_vect.pkl\")\n","    \n","    return df_train_vect, df_valid_vect, df_test_vect"]},{"cell_type":"code","execution_count":14,"id":"08141c73-4bcf-4089-b06b-c30955a1e32f","metadata":{"id":"08141c73-4bcf-4089-b06b-c30955a1e32f"},"outputs":[],"source":["param_vec = {'min_df':0.01, \n","             'vectorizer_file': 'vectorizer', \n","             'out_path': \"../output/\"}"]},{"cell_type":"code","execution_count":15,"id":"3898ed27-b5a3-45b2-a9a9-6399123a4ea2","metadata":{"id":"3898ed27-b5a3-45b2-a9a9-6399123a4ea2","outputId":"a4c2675d-41df-4482-8a6e-d723fef85c84"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nvic\\plds\\venv_plds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","c:\\Users\\nvic\\plds\\venv_plds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","c:\\Users\\nvic\\plds\\venv_plds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["x_train_vect, x_valid_vect, x_test_vect = main_feat(x_preprocessed_list, param_vec)"]},{"cell_type":"markdown","id":"da7b5374-aa13-4c86-a0d4-7de96590cf87","metadata":{"id":"da7b5374-aa13-4c86-a0d4-7de96590cf87"},"source":["# Modeling"]},{"cell_type":"markdown","id":"de46d18e-d09e-4ca5-975d-5d44a35881c6","metadata":{"id":"de46d18e-d09e-4ca5-975d-5d44a35881c6"},"source":["Functions to initiate classifier models"]},{"cell_type":"code","execution_count":null,"id":"9ee078c2-0b7c-4c38-bdd8-ed100520ca8b","metadata":{"id":"9ee078c2-0b7c-4c38-bdd8-ed100520ca8b"},"outputs":[],"source":["def model_logreg(class_weight = None):\n","    \"\"\"\n","    Function for initiating Logistic Regression Model\n","    \"\"\"\n","    param_dist = {'C' : [0.25, 0.5, 1]}\n","    base_model = LogisticRegression(random_state=42, solver='liblinear', class_weight=class_weight)\n","    \n","    return param_dist, base_model\n","\n","def model_rf(class_weight = None):\n","    \"\"\"\n","    Function for initiating Random Forest Model\n","    \"\"\"\n","    param_dist = {'n_estimators' : [25, 50, 100]}\n","    base_model = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight=class_weight)\n","    \n","    return param_dist, base_model\n","\n","def model_lgb(class_weight = None):\n","    \"\"\"\n","    Function for initiating LightGBM Model\n","    \"\"\"\n","    param_dist = {'n_estimators' : [25, 50, 100], 'boosting_type':['gbdt', 'goss']}\n","    base_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, class_weight=class_weight)\n","    \n","    return param_dist, base_model"]},{"cell_type":"markdown","id":"ffedf3cb-4520-4468-97f4-2a03c5ef656b","metadata":{"id":"ffedf3cb-4520-4468-97f4-2a03c5ef656b"},"source":["Base function for hyperparameter search and classifier calibration"]},{"cell_type":"code","execution_count":null,"id":"328b4f28-b863-4c44-974a-158e0d742110","metadata":{"id":"328b4f28-b863-4c44-974a-158e0d742110"},"outputs":[],"source":["def random_search_cv(model, param, scoring, n_iter, x, y, verbosity=0):\n","    \"\"\"\n","    Just a function to run the hyperparameter search\n","    \"\"\"\n","    random_fit = RandomizedSearchCV(estimator = model, \n","                                    param_distributions = param, \n","                                    scoring = scoring, \n","                                    n_iter = n_iter, \n","                                    cv = 5, \n","                                    random_state = 42, \n","                                    verbose = verbosity)\n","    random_fit.fit(x, y)\n","    return random_fit\n","\n","def calibrate_classifier(model, x_valid, y_valid):\n","    model_calibrated = CalibratedClassifierCV(model, cv='prefit')\n","    model_calibrated.fit(x_valid, y_valid)\n","    \n","    return model_calibrated"]},{"cell_type":"code","execution_count":null,"id":"2e204888-4636-4ec6-9c09-7e6b98972170","metadata":{"id":"2e204888-4636-4ec6-9c09-7e6b98972170"},"outputs":[],"source":["def tune_threshold(model, x_valid, y_valid, scorer):\n","    \"\"\"\n","    Function for threshold adjustment\n","    \n","    Args:\n","        - model(callable): Sklearn model\n","        - x_valid(DataFrame):\n","        - y_valid(DataFrame):\n","        - scorer(callable): Sklearn scorer function, for example: f1_score\n","        \n","    Returns:\n","    - metric_score(float): Maximum metric score\n","    - best_threshold(float): Best threshold value\n","    \"\"\"\n","    thresholds = np.linspace(0,1,101)\n","    proba = model.predict_proba(x_valid)[:, 1]\n","    proba = pd.DataFrame(proba)\n","    proba.columns = ['probability']\n","    score = []\n","    for threshold_value in thresholds:\n","        proba['prediction'] = np.where( proba['probability'] > threshold_value, 1, 0)\n","        metric_score = scorer(proba['prediction'], y_valid, average='macro')\n","        score.append(metric_score)\n","    metric_score = pd.DataFrame([thresholds,score]).T\n","    metric_score.columns = ['threshold','metric_score']\n","    best_score = (metric_score['metric_score'] == metric_score['metric_score'].max())\n","    best_threshold = metric_score[best_score]['threshold']\n","    \n","    return metric_score[\"metric_score\"].max(), best_threshold.values[0]\n","\n","def select_model(train_log_dict):\n","    \"\"\"\n","    Function for selecting best model\n","    \"\"\"\n","    max_score = max(train_log_dict['model_score'])\n","    max_index = train_log_dict['model_score'].index(max_score)\n","    best_model = train_log_dict['model_fit'][max_index]\n","    best_report = train_log_dict['model_report'][max_index]\n","    best_threshold = train_log_dict['threshold'][max_index]\n","    name = train_log_dict['model_name'][max_index]\n","\n","    return best_model, best_report, best_threshold, name"]},{"cell_type":"code","execution_count":null,"id":"356c5e51-a1cc-4a9b-9c04-3948dd719aae","metadata":{"id":"356c5e51-a1cc-4a9b-9c04-3948dd719aae"},"outputs":[],"source":["def classif_report(model_obj, x_test, y_test, best_threshold=None, calc_auc=True):\n","    code2rel = {'0': 'Non-Toxic', '1': 'Toxic'}\n","    \n","    if best_threshold is None:\n","        pred = model_obj.predict(x_test)\n","    else:\n","        proba = model_obj.predict_proba(x_test)[:, 1]\n","        pred = np.where(proba > best_threshold, 1, 0)\n","\n","    res = classification_report(\n","        y_test, pred, output_dict=True, zero_division=0)\n","    res = pd.DataFrame(res).rename(columns=code2rel).T\n","\n","    if calc_auc:\n","        proba = model_obj.predict_proba(x_test)[:, 1]\n","        auc_score = roc_auc_score(y_test, proba)\n","\n","        print(\n","            f\"AUC score: {auc_score}, F1-Macro: {res['f1-score']['macro avg']}\")\n","    return pred, res"]},{"cell_type":"markdown","id":"c2fc3e7c-b7af-4703-8bbb-3912d911a418","metadata":{"id":"c2fc3e7c-b7af-4703-8bbb-3912d911a418"},"source":["Create a wrapper function to fit and validate the model:\n","- Fit : Performs hyperparameter optimization for each model\n","- Validate: Calibrate model, tune model threshold, and validate model."]},{"cell_type":"code","execution_count":null,"id":"c3c070d1-5d52-449d-8172-39a3877a6364","metadata":{"id":"c3c070d1-5d52-449d-8172-39a3877a6364"},"outputs":[],"source":["def fit(x_train, y_train, model, model_param, scoring='f1', n_iter=3, verbosity=3):\n","    \"\"\"\n","    Fit model\n","    \n","    Args:\n","        - model(callable): sklearn model\n","        - model_param(dict): sklearn's RandomizedSearchCV params_distribution\n","    \n","    Return:\n","        - model_fitted(callable): model with optimum hyperparams\n","    \"\"\"\n","    model_fitted = random_search_cv(model, model_param, \n","                                    scoring, \n","                                    n_iter, \n","                                    x_train, y_train, \n","                                    verbosity)\n","    print(\n","        f'Model: {model_fitted.best_estimator_}, {scoring}: {model_fitted.best_score_}')\n","    \n","    return model_fitted\n","\n","def validate(x_valid, y_valid, model_fitted, tune = True):\n","    \"\"\"\n","    Validate model\n","\n","    Args:\n","        - x_valid(DataFrame): Validation independent variables\n","        - y_valid(DataFrame): Validation Dependent variables\n","        - model_fitted(callable): Sklearn / imblearn fitted model\n","        \n","    Return:\n","        - report_model: sklearn model report\n","        - model_calibrated(callable): Calibrated model\n","        - best_threshold(float): Best threshold\n","    \"\"\"\n","    code2rel = {'0': 'Non-Toxic', '1': 'Toxic'}\n","\n","    # Calibrate Classifier\n","    model_calibrated = CalibratedClassifierCV(base_estimator=model_fitted,\n","                                              cv=\"prefit\")\n","    model_calibrated.fit(x_valid, y_valid)\n","    \n","    if tune:\n","        metric_score, best_threshold = tune_threshold(model_calibrated,\n","                                                      x_valid,\n","                                                      y_valid,\n","                                                      f1_score)\n","        \n","        print(f'Best threshold is: {best_threshold}, with score: {metric_score}')\n","        pred_model, report_model = classif_report(model_calibrated,\n","                                                  x_valid,\n","                                                  y_valid,\n","                                                  best_threshold,\n","                                                  True)\n","    else:\n","        # Report default\n","        best_threshold = None\n","        pred_model, report_model = classif_report(\n","            model_calibrated, x_valid, y_valid, True)\n","\n","    return report_model, model_calibrated, best_threshold"]},{"cell_type":"markdown","id":"34811d6d-e81c-404f-92f0-08dc0f1314fa","metadata":{"id":"34811d6d-e81c-404f-92f0-08dc0f1314fa"},"source":["Main training function that executes the `fit` and `validate` functions:\n","- Drop the `id` column\n","- Compute class weight for imbalanced problem\n","- Create a logging dictionary\n","- Try each model: Fit and validate each model\n","- Select best performing model\n","- Dump model to pickle"]},{"cell_type":"code","execution_count":null,"id":"3c55d01c-67a7-40e1-8776-542f708253a6","metadata":{"id":"3c55d01c-67a7-40e1-8776-542f708253a6"},"outputs":[],"source":["def main(x_train, y_train, x_valid, y_valid, params):\n","    \n","    x_train = x_train.drop(columns='id')\n","    y_train = y_train.drop(columns='id')\n","    x_valid = x_valid.drop(columns='id')\n","    y_valid = y_valid.drop(columns='id')\n","    \n","    y_train = y_train.values.ravel()\n","    y_valid = y_valid.values.ravel()\n","\n","    # Add class weight\n","    if params['use_weight']:\n","        class_weight = compute_class_weight(class_weight = 'balanced', \n","                                            classes = np.unique(y_train), \n","                                            y = y_train)\n","        class_weights = dict(zip(np.unique(y_train), class_weight))\n","    else:\n","        class_weights = None\n","    \n","    # Initiate models\n","    logreg = model_logreg\n","    rf = model_rf\n","    lgb = model_lgb\n","    \n","    # Initiate logs\n","    train_log_dict = {'model': [logreg, rf, lgb],\n","                      'model_name': [],\n","                      'model_fit': [],\n","                      'model_report': [],\n","                      'model_score': [],\n","                      'threshold': [],\n","                      'fit_time': []}\n","\n","\n","    # Try Each models\n","    for model in train_log_dict['model']:\n","        param_model, base_model = model(class_weights)\n","        train_log_dict['model_name'].append(base_model.__class__.__name__)\n","        print(f'Fitting {base_model.__class__.__name__}')\n","\n","        # Train\n","        t0 = time.time()\n","        scoring = make_scorer(f1_score,average='macro')\n","        fitted_model = fit(\n","            x_train, y_train, base_model, param_model, \n","            scoring=scoring, verbosity=params['verbosity'])\n","        elapsed_time = time.time() - t0\n","        print(f'elapsed time: {elapsed_time} s \\n')\n","        train_log_dict['fit_time'].append(elapsed_time)\n","\n","        # Validate\n","        report, calibrated_model, best_threshold = validate(\n","            x_valid, y_valid, fitted_model)\n","        train_log_dict['model_fit'].append(calibrated_model)\n","        train_log_dict['threshold'].append(best_threshold)\n","        train_log_dict['model_report'].append(report)\n","        train_log_dict['model_score'].append(report['f1-score']['macro avg'])\n","\n","    best_model, best_report, best_threshold, name = select_model(\n","        train_log_dict)\n","    print(\n","        f\"Model: {name}, Score: {best_report['f1-score']['macro avg']}\")\n","    joblib.dump(best_model, params['out_path']+'mantab_model.pkl')\n","    joblib.dump(best_threshold, params['out_path']+'../model/threshold.pkl')\n","    joblib.dump(train_log_dict, params['out_path']+'../model/train_log.pkl')\n","    print(f'\\n {best_report}')\n","    \n","    return best_model\n"]},{"cell_type":"code","execution_count":null,"id":"c53682d7-377e-40c2-9933-8b928b52aad8","metadata":{"id":"c53682d7-377e-40c2-9933-8b928b52aad8"},"outputs":[],"source":["param_model={'use_weight':True, \n","             'verbosity':2, \n","             'out_path': \"../model/\"}"]},{"cell_type":"code","execution_count":null,"id":"da4d9251-e02c-42f0-9ae9-abc213170010","metadata":{"id":"da4d9251-e02c-42f0-9ae9-abc213170010","outputId":"7fa3eadc-6c5b-472b-a7ce-67463aee063d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting LogisticRegression\n","Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","[CV] END .............................................C=0.25; total time=   0.8s\n","[CV] END .............................................C=0.25; total time=   0.7s\n","[CV] END .............................................C=0.25; total time=   0.7s\n","[CV] END .............................................C=0.25; total time=   0.7s\n","[CV] END .............................................C=0.25; total time=   0.7s\n","[CV] END ..............................................C=0.5; total time=   0.7s\n","[CV] END ..............................................C=0.5; total time=   0.7s\n","[CV] END ..............................................C=0.5; total time=   0.7s\n","[CV] END ..............................................C=0.5; total time=   0.7s\n","[CV] END ..............................................C=0.5; total time=   0.8s\n","[CV] END ................................................C=1; total time=   0.8s\n","[CV] END ................................................C=1; total time=   0.8s\n","[CV] END ................................................C=1; total time=   0.8s\n","[CV] END ................................................C=1; total time=   0.7s\n","[CV] END ................................................C=1; total time=   0.7s\n","Model: LogisticRegression(C=0.25,\n","                   class_weight={0: 0.5524624642168604, 1: 5.265311804008909},\n","                   random_state=42, solver='liblinear'), make_scorer(f1_score, average=macro): 0.6421089289103569\n","elapsed time: 14.056023597717285 s \n","\n","Best threshold is: 0.28, with score: 0.7274590201066383\n","AUC score: 0.8707963639565767, F1-Macro: 0.7274590201066383\n","Fitting RandomForestClassifier\n","Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","[CV] END ....................................n_estimators=25; total time=  16.1s\n","[CV] END ....................................n_estimators=25; total time=  14.1s\n","[CV] END ....................................n_estimators=25; total time=  13.3s\n","[CV] END ....................................n_estimators=25; total time=  13.3s\n","[CV] END ....................................n_estimators=25; total time=  15.9s\n","[CV] END ....................................n_estimators=50; total time=  27.8s\n","[CV] END ....................................n_estimators=50; total time=  25.8s\n","[CV] END ....................................n_estimators=50; total time=  24.0s\n","[CV] END ....................................n_estimators=50; total time=  27.9s\n","[CV] END ....................................n_estimators=50; total time=  24.1s\n","[CV] END ...................................n_estimators=100; total time=  46.0s\n","[CV] END ...................................n_estimators=100; total time=  57.0s\n","[CV] END ...................................n_estimators=100; total time=  54.3s\n","[CV] END ...................................n_estimators=100; total time=  55.6s\n","[CV] END ...................................n_estimators=100; total time=  50.3s\n","Model: RandomForestClassifier(class_weight={0: 0.5524624642168604,\n","                                     1: 5.265311804008909},\n","                       n_jobs=-1, random_state=42), make_scorer(f1_score, average=macro): 0.6865090160448547\n","elapsed time: 526.5272305011749 s \n","\n","Best threshold is: 0.27, with score: 0.6877470733863128\n","AUC score: 0.8392941864478894, F1-Macro: 0.6877470733863128\n","Fitting LGBMClassifier\n","Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","[CV] END ................boosting_type=gbdt, n_estimators=25; total time=   2.4s\n","[CV] END ................boosting_type=gbdt, n_estimators=25; total time=   2.5s\n","[CV] END ................boosting_type=gbdt, n_estimators=25; total time=   3.5s\n","[CV] END ................boosting_type=gbdt, n_estimators=25; total time=   2.6s\n","[CV] END ................boosting_type=gbdt, n_estimators=25; total time=   2.4s\n","[CV] END ................boosting_type=gbdt, n_estimators=50; total time=   3.0s\n","[CV] END ................boosting_type=gbdt, n_estimators=50; total time=   2.9s\n","[CV] END ................boosting_type=gbdt, n_estimators=50; total time=   3.0s\n","[CV] END ................boosting_type=gbdt, n_estimators=50; total time=   2.9s\n","[CV] END ................boosting_type=gbdt, n_estimators=50; total time=   3.0s\n","[CV] END ...............boosting_type=goss, n_estimators=100; total time=   4.5s\n","[CV] END ...............boosting_type=goss, n_estimators=100; total time=   4.7s\n","[CV] END ...............boosting_type=goss, n_estimators=100; total time=   5.2s\n","[CV] END ...............boosting_type=goss, n_estimators=100; total time=   4.9s\n","[CV] END ...............boosting_type=goss, n_estimators=100; total time=   7.5s\n","Model: LGBMClassifier(boosting_type='goss',\n","               class_weight={0: 0.5524624642168604, 1: 5.265311804008909},\n","               random_state=42), make_scorer(f1_score, average=macro): 0.6384900218944738\n","elapsed time: 63.91648817062378 s \n","\n","Best threshold is: 0.34, with score: 0.7308314023042528\n","AUC score: 0.8734199814395895, F1-Macro: 0.7308314023042528\n","Model: LGBMClassifier, Score: 0.7308314023042528\n","\n","               precision    recall  f1-score       support\n","Non-Toxic      0.942593  0.969379  0.955798  39940.000000\n","Toxic          0.599804  0.437366  0.505864   4191.000000\n","accuracy       0.918855  0.918855  0.918855      0.918855\n","macro avg      0.771198  0.703372  0.730831  44131.000000\n","weighted avg   0.910039  0.918855  0.913069  44131.000000\n"]}],"source":["best_model = main(x_train_vect, y_train, x_valid_vect, y_valid, param_model)"]},{"cell_type":"markdown","id":"ecf733bb-59fe-481d-8abb-6a40759643aa","metadata":{"id":"ecf733bb-59fe-481d-8abb-6a40759643aa"},"source":["# Prediction\n","\n","To create prediction function, first, you must know how the data will be passed to the predictor. Often, it requires agreement from your Backend Engineer, MLOps Engineer, and Project manager.\n","\n","Let's assume that the data will be predicted one by one."]},{"cell_type":"code","execution_count":null,"id":"78c0b1f3-bf94-4c80-b293-b6085b6762a9","metadata":{"id":"78c0b1f3-bf94-4c80-b293-b6085b6762a9"},"outputs":[],"source":["# In the previous preprocessing, we work with DataFrame.\n","# It'll be easier for us to also work with DataFrame in the prediction stage\n","\n","def df_constructor(text, id=0):\n","    df = pd.DataFrame(data={'id':[id], 'comment_text':[text]})\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"69be98d9-ca59-41ab-9474-127350d5a307","metadata":{"id":"69be98d9-ca59-41ab-9474-127350d5a307"},"outputs":[],"source":["def main_predict(text, tfidf_vectorizer, model, threshold, param_preprocess, param_vec, id=0):\n","    df = df_constructor(text, id)\n","    df_preprocessed = preprocess(df, param_preprocess)\n","    df_vect, _ = vectorize_tfidf(df_preprocessed, param_vec, tfidf_vectorizer)\n","    \n","    code2rel = {0: 'Non-Toxic', 1: 'Toxic'}\n","    df_vect = df_vect.drop(columns='id')\n","    proba = model.predict_proba(df_vect)[:, 1]\n","    predict = 1 if proba > threshold else 0\n","    \n","    return code2rel[predict], proba"]},{"cell_type":"code","execution_count":null,"id":"03e8dd12-b7c7-42a5-a16b-4435f1ccefab","metadata":{"id":"03e8dd12-b7c7-42a5-a16b-4435f1ccefab"},"outputs":[],"source":["tfidf_vect = joblib.load(\"../output/vectorizer.pkl\")\n","model = joblib.load('../model/mantab_model.pkl')\n","threshold = joblib.load('../model/threshold.pkl')"]},{"cell_type":"code","execution_count":null,"id":"1e251e43-860e-46d9-8390-3d13da90e697","metadata":{"id":"1e251e43-860e-46d9-8390-3d13da90e697","outputId":"19a52e87-1b65-4056-a082-dc62b64069dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\users\\ghifa\\documents\\pacmann\\simple-ml-project-example\\projectenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["text = \"fuck fuck fuck you cunt, you can't do anything but whining, you useless trash piece of shit.\"\n","predict, proba = main_predict(text, tfidf_vect, model, threshold, params_preprocess, param_vec)"]},{"cell_type":"code","execution_count":null,"id":"4a9e8903-0fb5-4ab6-8664-1ee965d29aeb","metadata":{"id":"4a9e8903-0fb5-4ab6-8664-1ee965d29aeb","outputId":"960ce6d3-427c-4029-e878-a017299fb754"},"outputs":[{"data":{"text/plain":["'Toxic'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["predict"]},{"cell_type":"code","execution_count":null,"id":"10edecc1-eae9-4cf4-82cd-1482381847d5","metadata":{"id":"10edecc1-eae9-4cf4-82cd-1482381847d5"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"notebook_materi_5.ipynb","provenance":[]},"interpreter":{"hash":"9f33b21f908247f542bd91282131d87d490440b32a35c0a350be5be18b0aecfe"},"kernelspec":{"display_name":"Python 3.9.13 ('venv_plds': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
